{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning / Aprendizagem Automática\n",
    "\n",
    "## Diogo Soares, André Falcão and Sara C. Madeira, 2020/21\n",
    "\n",
    "# ML Project  - Learning about Donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset to be analysed is **`Donors_dataset.csv`**, made available together with this project description. This dataset, downloaded from [Kaggle](https://www.kaggle.com), contains selected data from the following dataset: [Donors-Prediction](https://www.kaggle.com/momohmustapha/donorsprediction/). \n",
    "\n",
    "\n",
    "**In this project, your team is supposed to use only tabular data (not Images or Image Metadata) and see how far you can go in predicting donations and understanding the donors. You should use both supervised and unsupervised learning to tackled 2 tasks:**\n",
    "\n",
    "1. **Task 1 (Supervised Learning) - Predicting Donation and Donation Type**\n",
    "2. **Task 2 (Unsupervised Learning) - Characterizing Donors**\n",
    "\n",
    "The **`Donors_dataset.csv`** you should learn from has **19.372 instances** described by **50 data fields** that you might use as **categorical/numerical features** \n",
    "\n",
    "### File Descriptions\n",
    "\n",
    "* **Donors_dataset.csv** - Tabular/text data to be used in the machine learning tasks.\n",
    "\n",
    "\n",
    "### Data Fields\n",
    "\n",
    "* **CARD_PROM_12** - number of card promotions sent to the individual by the charitable organization in the past 12 months\n",
    "* **CLUSTER_CODE** - one of 54 possible cluster codes, which are unique in terms of socioeconomic status, urbanicity, ethnicity, and other demographic characteristics\n",
    "* **CONTROL_NUMBER** - unique identifier of each individual\n",
    "* **DONOR_AGE** - age as of last year's mail solicitation\n",
    "* **DONOR_GENDER** - actual or inferred gender\n",
    "* **FILE_AVG_GIFT** - this variable is identical to LIFETIME_AVG_GIFT_AMT\n",
    "* **FILE_CARD_GIFT** - lifetime average donation (in \\\\$) from the individual in response to all card solicitations from the charitable organization\n",
    "* **FREQUENCY_STATUS_97NK** - based on the period of recency (determined by RECENCY_STATUS_96NK), which is the past 12 months for all groups except L and E. L and E are 13–24 months ago and 25–36 months ago, respectively: 1 if one donation in this period, 2 if two donations in this period, 3 if three donations in this period, and 4 if four or more donations in this period.\n",
    "* **HOME_OWNER** - H if the individual is a homeowner, U if this information is unknown\n",
    "* **INCOME_GROUP** - one of 7 possible income level groups based on a number of demographic characteristics\n",
    "* **IN_HOUSE** - 1 if the individual has ever donated to the charitable organization's In House program, 0 if not\n",
    "* **LAST_GIFT_AMT** - amount of the most recent donation from the individual to the charitable organization\n",
    "* **LIFETIME_AVG_GIFT_AMT** - lifetime average donation (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_CARD_PROM** - total number of card promotions sent to the individual by the charitable organization\n",
    "* **LIFETIME_GIFT_AMOUNT** - total lifetime donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_COUNT** - total number of donations from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_RANGE** - maximum donation amount from the individual minus minimum donation amount from the individual\n",
    "* **LIFETIME_MAX_GIFT_AMT** - maximum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_MIN_GIFT_AMT** - minimum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_PROM** - total number of promotions sent to the individual by the charitable organization\n",
    "* **MEDIAN_HOME_VALUE** - median home value (in 100\\\\$) as determined by other input variables\n",
    "* **MEDIAN_HOUSEHOLD_INCOME** - median household income (in 100\\\\$) as determined by other input variables\n",
    "* **MONTHS_SINCE_FIRST_GIFT** - number of months since the first donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_GIFT** - number of months since the most recent donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_PROM_RESP** - number of months since the individual has responded to a promotion by the charitable organization\n",
    "* **MONTHS_SINCE_ORIGIN** - number of months that the individual has been in the charitable organization's database\n",
    "* **MOR_HIT_RATE** - total number of known times the donor has responded to a mailed solicitation from a group other than the charitable organization\n",
    "* **NUMBER_PROM_12** - number of promotions (card or other) sent to the individual by the charitable organization in the past 12 months\n",
    "* **OVERLAY_SOURCE** - the data source against which the individual was matched: M if Metromail, P if Polk, B if both\n",
    "* **PCT_ATTRIBUTE1** - percent of residents in the neighborhood in which the individual lives that are males and active military\n",
    "* **PCT_ATTRIBUTE2** - percent of residents in the neighborhood in which the individual lives that are males and veterans\n",
    "* **PCT_ATTRIBUTE3** - percent of residents in the neighborhood in which the individual lives that are Vietnam veterans\n",
    "* **PCT_ATTRIBUTE4** - percent of residents in the neighborhood in which the individual lives that are WWII veterans\n",
    "* **PCT_OWNER_OCCUPIED** - percent of owner-occupied housing in the neighborhood in which the individual lives\n",
    "* **PEP_STAR** - 1 if individual has ever achieved STAR donor status, 0 if not\n",
    "* **PER_CAPITA_INCOME** - per capita income (in \\\\$) of the neighborhood in which the individual lives\n",
    "* **PUBLISHED_PHONE** - 1 if the individual's telephone number is published, 0 if not\n",
    "* **RECENCY_STATUS_96NK** - recency status as of two years ago: A if active donor, S if star donor, N if new donor, E if inactive donor, F if first time donor, L if lapsing donor\n",
    "* **RECENT_AVG_CARD_GIFT_AMT** - average donation from the individual in response to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_AVG_GIFT_AMT** - average donation (in \\\\$) from the individual to the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_COUNT** - number of times the individual has responded to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_PROP** - proportion of responses to the individual to the number of card solicitations from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_COUNT** - number of times the individual has responded to a promotion (card or other) from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_PROP** - proportion of responses to the individual to the number of (card or other) solicitations from the charitable organization since four years ago\n",
    "* **RECENT_STAR_STATUS** - 1 if individual has achieved star donor status since four years ago, 0 if not\n",
    "* **SES** - one of 5 possible socioeconomic codes classifying the neighborhood in which the individual lives\n",
    "* **TARGET_B** - 1 if individual donated in response to last year's 97NK mail solicitation from the charitable organization, 0 if individual did not\n",
    "* **TARGET_D** - amount of donation (in \\\\$) from the individual in response to last year's 97NK mail solicitation from the charitable organization\n",
    "* **URBANICITY** - classification of the neighborhood in which the individual lives: U if urban, C if city, S if suburban, T if town, R if rural, ? if missing\n",
    "* **WEALTH_RATING** - one of 10 possible wealth rating groups based on a number of demographic characteristics\n",
    "\n",
    "\n",
    "### Donation TYPE\n",
    "\n",
    "You are supposed to create a new column/feature named `DONATION_TYPE`, whose values describe ranges of the donation amount (DA) reported in feature `TARGET_D`:\n",
    "* `A` - DA >= 50\n",
    "* `B` - 20 <= DA < 50 \n",
    "* `C` - 13 <= DA < 20\n",
    "* `D` - 10 <= DA < 13\n",
    "* `E` - DA < 10\n",
    "\n",
    "\n",
    "### **Important Notes on Data Cleaning and Preprocessing**\n",
    "\n",
    "   1. Data can contain **errors/typos**, whose correction might improve the analysis.\n",
    "   2. Some features can contain **many values**, whose grouping in categories (aggregation into bins) might improve the analysis.\n",
    "   3. Data can contain **missing values**, that you might decide to fill. You might also decide to eliminate instances/features with high percentages of missing values.\n",
    "   4. **Not all features are necessarily important** for the analysis.\n",
    "   5. Depending on the analysis, **some features might have to be excluded**.\n",
    "   6. Class distribution is an important characteristic of the dataset that should be checked. **Class imbalance** might impair machine learning. \n",
    "  \n",
    "Some potentially useful links:\n",
    "\n",
    "* Data Cleaning and Preprocessing in Scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "* Data Cleaning and Preprocessing in Orange: https://docs.biolab.si//3/visual-programming/widgets/data/preprocess.html\n",
    "* Dealing with imbalance datasets: https://pypi.org/project/imbalanced-learn/ and https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.622519Z",
     "start_time": "2020-12-30T23:47:57.031102Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.768829Z",
     "start_time": "2020-12-30T23:47:59.626765Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fname, missing_values = None):\n",
    "    \"\"\"Load CSV file with any number of consecutive features, starting in column 0, where last column is tha class\"\"\"\n",
    "    df = pd.read_csv(fname, na_values = missing_values)\n",
    "    return df\n",
    "\n",
    "df = load_data('Donors_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.785573Z",
     "start_time": "2020-12-30T23:47:59.771390Z"
    }
   },
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **understand better the features**, their distribution of values, potential errors, etc and plan/describe what data preprocessing steps should be performed next. Very important also is to check the distribution of values in the target (class distribution). \n",
    "\n",
    "Here you can find a notebook with some examples of what you can do in **Exploratory Data Analysis**: https://www.kaggle.com/artgor/exploration-of-data-step-by-step/notebook. You can also use Orange widgets for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.836608Z",
     "start_time": "2020-12-30T23:47:59.789462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>CONTROL_NUMBER</th>\n",
       "      <th>MONTHS_SINCE_ORIGIN</th>\n",
       "      <th>DONOR_AGE</th>\n",
       "      <th>IN_HOUSE</th>\n",
       "      <th>URBANICITY</th>\n",
       "      <th>SES</th>\n",
       "      <th>CLUSTER_CODE</th>\n",
       "      <th>HOME_OWNER</th>\n",
       "      <th>...</th>\n",
       "      <th>LIFETIME_GIFT_RANGE</th>\n",
       "      <th>LIFETIME_MAX_GIFT_AMT</th>\n",
       "      <th>LIFETIME_MIN_GIFT_AMT</th>\n",
       "      <th>LAST_GIFT_AMT</th>\n",
       "      <th>CARD_PROM_12</th>\n",
       "      <th>NUMBER_PROM_12</th>\n",
       "      <th>MONTHS_SINCE_LAST_GIFT</th>\n",
       "      <th>MONTHS_SINCE_FIRST_GIFT</th>\n",
       "      <th>FILE_AVG_GIFT</th>\n",
       "      <th>FILE_CARD_GIFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>101</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>.</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>92</td>\n",
       "      <td>8.49</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>137</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>14.72</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>113</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>16.75</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>11.76</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>101</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>U</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>92</td>\n",
       "      <td>8.83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_B  TARGET_D  CONTROL_NUMBER  MONTHS_SINCE_ORIGIN  DONOR_AGE  \\\n",
       "0         0       NaN               5                  101       87.0   \n",
       "1         1      10.0              12                  137       79.0   \n",
       "2         0       NaN              37                  113       75.0   \n",
       "3         0       NaN              38                   92        NaN   \n",
       "4         0       NaN              41                  101       74.0   \n",
       "\n",
       "   IN_HOUSE URBANICITY SES CLUSTER_CODE HOME_OWNER  ... LIFETIME_GIFT_RANGE  \\\n",
       "0         0          ?   ?            .          H  ...                15.0   \n",
       "1         0          R   2           45          H  ...                20.0   \n",
       "2         0          S   1           11          H  ...                23.0   \n",
       "3         0          U   2            4          H  ...                14.0   \n",
       "4         0          R   2           49          U  ...                20.0   \n",
       "\n",
       "   LIFETIME_MAX_GIFT_AMT  LIFETIME_MIN_GIFT_AMT LAST_GIFT_AMT  CARD_PROM_12  \\\n",
       "0                   20.0                    5.0          15.0             5   \n",
       "1                   25.0                    5.0          17.0             7   \n",
       "2                   28.0                    5.0          19.0            11   \n",
       "3                   17.0                    3.0          15.0            11   \n",
       "4                   25.0                    5.0          25.0             6   \n",
       "\n",
       "   NUMBER_PROM_12  MONTHS_SINCE_LAST_GIFT  MONTHS_SINCE_FIRST_GIFT  \\\n",
       "0              12                      26                       92   \n",
       "1              21                       7                      122   \n",
       "2              32                       6                      105   \n",
       "3              33                       6                       92   \n",
       "4              19                      18                       92   \n",
       "\n",
       "   FILE_AVG_GIFT  FILE_CARD_GIFT  \n",
       "0           8.49               7  \n",
       "1          14.72              12  \n",
       "2          16.75              16  \n",
       "3          11.76              12  \n",
       "4           8.83               3  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset in tabular format to have a general view of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Errors/Typos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are identifying errors and typos present in the data using the np.unique() method. We can learn which elements are incorrect based on the available information from the dataset. Subsequently, these values can be considered missing values and assigned as such for posterior cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.921480Z",
     "start_time": "2020-12-30T23:47:59.839452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?' 'C' 'R' 'S' 'T' 'U']\n",
      "['1' '2' '3' '4' '?']\n",
      "['.' '1' '10' '11' '12' '13' '14' '15' '16' '17' '18' '19' '2' '20' '21'\n",
      " '22' '23' '24' '25' '26' '27' '28' '29' '3' '30' '31' '32' '33' '34' '35'\n",
      " '36' '37' '38' '39' '4' '40' '41' '42' '43' '44' '45' '46' '47' '48' '49'\n",
      " '5' '50' '51' '52' '53' '6' '7' '8' '9']\n",
      "['H' 'U']\n",
      "['A' 'F' 'M' 'U']\n",
      "['B' 'M' 'N' 'P']\n",
      "['A' 'E' 'F' 'L' 'N' 'S']\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        print(np.unique(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.934654Z",
     "start_time": "2020-12-30T23:47:59.924459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['DONOR_GENDER'] == 'A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information available for the DONOR_GENDER feature, we can assume that 'F', 'M' and 'U' stand for _Female_ , _Male_ and _Unknown_ , respectively. In addition, there is only one entry with the element 'A' in that column. Thus, 'A' will be considered as a typo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:47:59.948005Z",
     "start_time": "2020-12-30T23:47:59.938075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['MONTHS_SINCE_LAST_PROM_RESP'].loc[df['MONTHS_SINCE_LAST_PROM_RESP'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature MONTHS_SINCE_LAST_PROM_RESP should only present positive values of integer type as it stores a count for the number of months since an individual responded to a promotion from a charity. However, in 8 entries we found negative values. One possibility is that the '-' was a typo, yet the information available is not enough to make this assumption. Therefore we will treat these entries as missing values as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Assignemnt as NaNs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy to assign missing values is during the loading process. As displayed in the following output, the NaNs are converted while the .csv file is being read. In section 2.3 we will continue this process resorting to a different method for assignment of NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.138638Z",
     "start_time": "2020-12-30T23:47:59.953455Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_values = ['?','.']\n",
    "df = load_data('Donors_dataset.csv', missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can confirm that the previously identified typos are correctly read as missing values when the dataset is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.156238Z",
     "start_time": "2020-12-30T23:48:00.142457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 45. 11.  4. 49.  8. 50. 28. 30. 43. 53. 42. 46. 20. 16. 40.  7. 34.\n",
      " 23. 35. 41. 25. 10.  1.  9.  2. 12. 14. 37. 36. 15. 39. 38. 18. 48. 24.\n",
      "  3. 13. 31.  5. 27. 19. 51. 22. 17. 26. 21. 44.  6. 29. 33. 47. 32. 52.]\n",
      "[nan 'R' 'S' 'U' 'C' 'T']\n",
      "[nan  2.  1.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "print(df['CLUSTER_CODE'].unique())\n",
    "print(df['URBANICITY'].unique())\n",
    "print(df['SES'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Redundant / Unnecessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply by analysing the information from the dataset and considering the tasks at hand, some features can already be viewed as redundant or unnecessary. Such columns can be dropped from the start, reducing the size of the dataset for an easier handle on the data. Naturally, additional columns and elements may be dropped throughout the course of the project should it be deemed necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the following features:\n",
    "- FILE_AVG_GIFT - Identical to 'LIFETIME_AVG_GIFT_AMT'. It is redundant data;\n",
    "- PUBLISHED_PHONE - Not relevant for our tasks;\n",
    "- LIFETIME_MIN_GIFT_AMT - Represented in 'LIFETIME_GIFT_RANGE'. It is redundant data;\n",
    "- LIFETIME_MAX_GIFT_AMT - Represented in 'LIFETIME_GIFT_RANGE'. It is redundant data;\n",
    "- CONTROL_NUMBER - Unique identifier. Not relevant for our tasks;\n",
    "- HOME OWNER - Entries are either _Unknown_ ('U') or _Home Owners_ ('H'). Therefore, the information is not clear and will not be relevant for out tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.220770Z",
     "start_time": "2020-12-30T23:48:00.159659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>MONTHS_SINCE_ORIGIN</th>\n",
       "      <th>DONOR_AGE</th>\n",
       "      <th>IN_HOUSE</th>\n",
       "      <th>URBANICITY</th>\n",
       "      <th>SES</th>\n",
       "      <th>CLUSTER_CODE</th>\n",
       "      <th>DONOR_GENDER</th>\n",
       "      <th>INCOME_GROUP</th>\n",
       "      <th>...</th>\n",
       "      <th>LIFETIME_GIFT_AMOUNT</th>\n",
       "      <th>LIFETIME_GIFT_COUNT</th>\n",
       "      <th>LIFETIME_AVG_GIFT_AMT</th>\n",
       "      <th>LIFETIME_GIFT_RANGE</th>\n",
       "      <th>LAST_GIFT_AMT</th>\n",
       "      <th>CARD_PROM_12</th>\n",
       "      <th>NUMBER_PROM_12</th>\n",
       "      <th>MONTHS_SINCE_LAST_GIFT</th>\n",
       "      <th>MONTHS_SINCE_FIRST_GIFT</th>\n",
       "      <th>FILE_CARD_GIFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>297.0</td>\n",
       "      <td>35</td>\n",
       "      <td>8.49</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>92</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>368.0</td>\n",
       "      <td>25</td>\n",
       "      <td>14.72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>603.0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.75</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>U</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>F</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>435.0</td>\n",
       "      <td>37</td>\n",
       "      <td>11.76</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.83</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_B  TARGET_D  MONTHS_SINCE_ORIGIN  DONOR_AGE  IN_HOUSE URBANICITY  \\\n",
       "0         0       NaN                  101       87.0         0        NaN   \n",
       "1         1      10.0                  137       79.0         0          R   \n",
       "2         0       NaN                  113       75.0         0          S   \n",
       "3         0       NaN                   92        NaN         0          U   \n",
       "4         0       NaN                  101       74.0         0          R   \n",
       "\n",
       "   SES  CLUSTER_CODE DONOR_GENDER  INCOME_GROUP  ... LIFETIME_GIFT_AMOUNT  \\\n",
       "0  NaN           NaN            M           2.0  ...                297.0   \n",
       "1  2.0          45.0            M           7.0  ...                368.0   \n",
       "2  1.0          11.0            F           5.0  ...                603.0   \n",
       "3  2.0           4.0            F           6.0  ...                435.0   \n",
       "4  2.0          49.0            F           2.0  ...                106.0   \n",
       "\n",
       "   LIFETIME_GIFT_COUNT  LIFETIME_AVG_GIFT_AMT  LIFETIME_GIFT_RANGE  \\\n",
       "0                   35                   8.49                 15.0   \n",
       "1                   25                  14.72                 20.0   \n",
       "2                   36                  16.75                 23.0   \n",
       "3                   37                  11.76                 14.0   \n",
       "4                   12                   8.83                 20.0   \n",
       "\n",
       "   LAST_GIFT_AMT  CARD_PROM_12  NUMBER_PROM_12  MONTHS_SINCE_LAST_GIFT  \\\n",
       "0           15.0             5              12                      26   \n",
       "1           17.0             7              21                       7   \n",
       "2           19.0            11              32                       6   \n",
       "3           15.0            11              33                       6   \n",
       "4           25.0             6              19                      18   \n",
       "\n",
       "   MONTHS_SINCE_FIRST_GIFT  FILE_CARD_GIFT  \n",
       "0                       92               7  \n",
       "1                      122              12  \n",
       "2                      105              16  \n",
       "3                       92              12  \n",
       "4                       92               3  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns\n",
    "to_drop=['FILE_AVG_GIFT', 'PUBLISHED_PHONE', 'LIFETIME_MAX_GIFT_AMT','LIFETIME_MIN_GIFT_AMT', \n",
    "         'CONTROL_NUMBER','HOME_OWNER']\n",
    "df.drop(columns = to_drop, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section 2.1 we assigned the symbols _?_ and _._ as missing values during the loading process. Now we can compute the number of NaN currently present in the dataset and learn where they are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.286662Z",
     "start_time": "2020-12-30T23:48:00.224099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_D 14529\n",
      "DONOR_AGE 4795\n",
      "URBANICITY 454\n",
      "SES 454\n",
      "CLUSTER_CODE 454\n",
      "INCOME_GROUP 4392\n",
      "WEALTH_RATING 8810\n",
      "MONTHS_SINCE_LAST_PROM_RESP 246\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if np.any(df[col].isnull()):\n",
    "        print(col ,df[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.304436Z",
     "start_time": "2020-12-30T23:48:00.290479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['TARGET_B'] == 0]) == df['TARGET_D'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TARGET_D has a great number of missing values. However, they seem to correspond to individuals who are not donors, an information given by the column TARGET_B (TARGET_B == 0). Therefore, no action/imputation is needed in regard to these NaNs. We will replace them with the value _0_ to not be confused with 'real' NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.315368Z",
     "start_time": "2020-12-30T23:48:00.307929Z"
    }
   },
   "outputs": [],
   "source": [
    "df['TARGET_D'].replace(np.nan, 0, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.333305Z",
     "start_time": "2020-12-30T23:48:00.318700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14529"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This value should be identical to the number of missing values presented before the replacement.\n",
    "len(df.loc[df['TARGET_D'] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Assignment as NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features DONOR_GENDER and RECENCY_STATUS_96NK present _Unknown_ ('U') and _Lapsing_ ('L') to describe unknown data. Therefore, we will consider this information as missing and assign entries containing these strings as NaNs with the pd.replace() method. The typos previously identified in the columns 'DONOR_GENDER' and 'MONTHS_SINCE_LAST_PROM_RESP' will also be assigned as NaNs using the same funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.360154Z",
     "start_time": "2020-12-30T23:48:00.336748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05249845137311584\n",
      "0.004800743340904398\n",
      "5.162089613875697e-05\n",
      "0.00041296716911005574\n"
     ]
    }
   ],
   "source": [
    "# Proportion of values to be converted as NaNs\n",
    "print(len(df.loc[df['DONOR_GENDER'] == 'U'])/len(df['DONOR_GENDER']))\n",
    "print(len(df.loc[df['RECENCY_STATUS_96NK'] == 'L'])/len(df['RECENCY_STATUS_96NK'] ))\n",
    "print(len(df.loc[df['DONOR_GENDER'] == 'A'])/len(df['DONOR_GENDER']))\n",
    "print(len(df.loc[df['MONTHS_SINCE_LAST_PROM_RESP'] < 0])/len(df['MONTHS_SINCE_LAST_PROM_RESP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.379331Z",
     "start_time": "2020-12-30T23:48:00.362904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'F' nan 'A']\n",
      "['A' 'S' 'F' 'E' 'N' nan]\n",
      "['M' 'F' nan]\n"
     ]
    }
   ],
   "source": [
    "# Assigment as NaNs for the columns 'DONOR_GENDER','RECENCY_STATUS_96NK', 'DONOR_GENDER'.\n",
    "cols = ['DONOR_GENDER','RECENCY_STATUS_96NK', 'DONOR_GENDER']\n",
    "char = ['U','L','A']\n",
    "\n",
    "for col, ch in zip(cols, char):\n",
    "    df[col].replace(ch, np.nan, inplace=True)\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.391362Z",
     "start_time": "2020-12-30T23:48:00.382676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MONTHS_SINCE_LAST_PROM_RESP'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, there are already NaNs in the MONTHS_SINCE_LAST_PROM_RESP column. Thus, after adding the negative numbers the total count for missing values should increase to 254."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.421017Z",
     "start_time": "2020-12-30T23:48:00.394132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MONTHS_SINCE_LAST_PROM_RESP'].where(df['MONTHS_SINCE_LAST_PROM_RESP'] > 0, np.nan, inplace = True)\n",
    "df['MONTHS_SINCE_LAST_PROM_RESP'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.456792Z",
     "start_time": "2020-12-30T23:48:00.429693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.052550072269254594\n",
      "0.004800743340904398\n",
      "0.01311170761924427\n"
     ]
    }
   ],
   "source": [
    "# Proportion of missing NaNs. \n",
    "# It should be the same as the proportions computed above, except for the 'MONTHS_SINCE_LAST_PROM_RESP' column.\n",
    "print(df['DONOR_GENDER'].isnull().sum()/len(df['DONOR_GENDER']))\n",
    "print(df['RECENCY_STATUS_96NK'].isnull().sum()/len(df['RECENCY_STATUS_96NK']))\n",
    "print(df['MONTHS_SINCE_LAST_PROM_RESP'].isnull().sum()/len(df['MONTHS_SINCE_LAST_PROM_RESP']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a clear view on the percentage of NaNs present in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.526321Z",
     "start_time": "2020-12-30T23:48:00.459950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONOR_AGE 24.75 %\n",
      "URBANICITY 2.34 %\n",
      "SES 2.34 %\n",
      "CLUSTER_CODE 2.34 %\n",
      "DONOR_GENDER 5.26 %\n",
      "INCOME_GROUP 22.67 %\n",
      "WEALTH_RATING 45.48 %\n",
      "RECENCY_STATUS_96NK 0.48 %\n",
      "MONTHS_SINCE_LAST_PROM_RESP 1.31 %\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if np.any(df[col].isnull()):\n",
    "        print(col ,round(df[col].isnull().sum()/len(df[col])*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 NaNs Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T18:11:41.508812Z",
     "start_time": "2020-12-20T18:11:41.491196Z"
    }
   },
   "source": [
    "Depending on the column and the proportion of NaN, we can use different methods to treat the missing values, such as deletion and imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.543152Z",
     "start_time": "2020-12-30T23:48:00.529825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[df['CLUSTER_CODE'].isnull()].tolist() == df.index[df['SES'].isnull()].tolist() == df.index[df['URBANICITY'].isnull()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'MONTHS_SINCE_LAST_PROM_RESP', 'RECENCY_STATUS_96NK', and 'DONOR_GENDER' have a relatively low percentage of NaNs. In addition, the NaNs found in the columns 'CLUSTER_CODE', 'SES' and 'URBANICITY' are coincident. Thus, we will discard these rows. As for the WEALTH_RATING column, it contains 45 % of NaNs which is a considerably high amount. Therefore, we are discarding the entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.615584Z",
     "start_time": "2020-12-30T23:48:00.546164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Strategy: Dropping rows/columns with NaNs\n",
    "df.drop(df[df['MONTHS_SINCE_LAST_PROM_RESP'].isnull()].index, inplace = True)\n",
    "df.drop(df[df['RECENCY_STATUS_96NK'].isnull()].index, inplace = True)\n",
    "df.drop(df[df['CLUSTER_CODE'].isnull()].index, inplace = True)\n",
    "df.drop(df[df['DONOR_GENDER'].isnull()].index, inplace = True)\n",
    "df.drop(columns = ['WEALTH_RATING'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.663952Z",
     "start_time": "2020-12-30T23:48:00.627994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONOR_AGE 22.904488962033938 %\n",
      "INCOME_GROUP 20.481243970262756 %\n"
     ]
    }
   ],
   "source": [
    "# Remaining columns with missing data\n",
    "for col in df.columns:\n",
    "    if np.any(df[col].isnull()):\n",
    "        print(col ,df[col].isnull().sum()/len(df[col])*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the features DONOR_AGE and INCOME_GROUP we will impute the missing values through Multivariate Feature Imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding of categorical columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To procede with the imputation, it is necessary to encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.697398Z",
     "start_time": "2020-12-30T23:48:00.671000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URBANICITY\n",
      "DONOR_GENDER\n",
      "OVERLAY_SOURCE\n",
      "RECENCY_STATUS_96NK\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.752849Z",
     "start_time": "2020-12-30T23:48:00.700580Z"
    }
   },
   "outputs": [],
   "source": [
    "# Columns to encode: URBANICITY, OVERLAY_SOURCE, RECENCY_STATUS_96NK\n",
    "ord_enc = OrdinalEncoder()\n",
    "df[\"URBANICITY_e\"] = ord_enc.fit_transform(df[[\"URBANICITY\"]])\n",
    "df[\"DONOR_GENDER_e\"] = ord_enc.fit_transform(df[[\"DONOR_GENDER\"]])\n",
    "df[\"OVERLAY_SOURCE_e\"] = ord_enc.fit_transform(df[[\"OVERLAY_SOURCE\"]])\n",
    "df[\"RECENCY_STATUS_96NK_e\"] = ord_enc.fit_transform(df[[\"RECENCY_STATUS_96NK\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.790621Z",
     "start_time": "2020-12-30T23:48:00.760409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 4. 0. 3.]\n",
      "[1. 0.]\n",
      "[3. 0. 2. 1.]\n",
      "[4. 0. 2. 1. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"URBANICITY_e\"].unique())\n",
    "print(df[\"DONOR_GENDER_e\"].unique())\n",
    "print(df[\"OVERLAY_SOURCE_e\"].unique())\n",
    "print(df[\"RECENCY_STATUS_96NK_e\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.813929Z",
     "start_time": "2020-12-30T23:48:00.796239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset with both encoded and decoded variables\n",
    "df_original_encode = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.888898Z",
     "start_time": "2020-12-30T23:48:00.817445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>MONTHS_SINCE_ORIGIN</th>\n",
       "      <th>DONOR_AGE</th>\n",
       "      <th>IN_HOUSE</th>\n",
       "      <th>SES</th>\n",
       "      <th>CLUSTER_CODE</th>\n",
       "      <th>INCOME_GROUP</th>\n",
       "      <th>MOR_HIT_RATE</th>\n",
       "      <th>MEDIAN_HOME_VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>LAST_GIFT_AMT</th>\n",
       "      <th>CARD_PROM_12</th>\n",
       "      <th>NUMBER_PROM_12</th>\n",
       "      <th>MONTHS_SINCE_LAST_GIFT</th>\n",
       "      <th>MONTHS_SINCE_FIRST_GIFT</th>\n",
       "      <th>FILE_CARD_GIFT</th>\n",
       "      <th>URBANICITY_e</th>\n",
       "      <th>DONOR_GENDER_e</th>\n",
       "      <th>OVERLAY_SOURCE_e</th>\n",
       "      <th>RECENCY_STATUS_96NK_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>122</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2388</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>514</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_B  TARGET_D  MONTHS_SINCE_ORIGIN  DONOR_AGE  IN_HOUSE  SES  \\\n",
       "1         1      10.0                  137       79.0         0  2.0   \n",
       "2         0       0.0                  113       75.0         0  1.0   \n",
       "3         0       0.0                   92        NaN         0  2.0   \n",
       "4         0       0.0                  101       74.0         0  2.0   \n",
       "5         0       0.0                  101       63.0         0  3.0   \n",
       "\n",
       "   CLUSTER_CODE  INCOME_GROUP  MOR_HIT_RATE  MEDIAN_HOME_VALUE  ...  \\\n",
       "1          45.0           7.0             0                334  ...   \n",
       "2          11.0           5.0             0               2388  ...   \n",
       "3           4.0           6.0             0               1688  ...   \n",
       "4          49.0           2.0             8                514  ...   \n",
       "5           8.0           3.0             0                452  ...   \n",
       "\n",
       "   LAST_GIFT_AMT  CARD_PROM_12  NUMBER_PROM_12  MONTHS_SINCE_LAST_GIFT  \\\n",
       "1           17.0             7              21                       7   \n",
       "2           19.0            11              32                       6   \n",
       "3           15.0            11              33                       6   \n",
       "4           25.0             6              19                      18   \n",
       "5           10.0             9              20                      19   \n",
       "\n",
       "   MONTHS_SINCE_FIRST_GIFT  FILE_CARD_GIFT  URBANICITY_e  DONOR_GENDER_e  \\\n",
       "1                      122              12           1.0             1.0   \n",
       "2                      105              16           2.0             0.0   \n",
       "3                       92              12           4.0             0.0   \n",
       "4                       92               3           1.0             0.0   \n",
       "5                       91               6           4.0             1.0   \n",
       "\n",
       "   OVERLAY_SOURCE_e  RECENCY_STATUS_96NK_e  \n",
       "1               3.0                    4.0  \n",
       "2               3.0                    4.0  \n",
       "3               0.0                    0.0  \n",
       "4               0.0                    0.0  \n",
       "5               3.0                    0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset with categorical variables encoded\n",
    "df.drop(columns = [\"URBANICITY\",\"DONOR_GENDER\",\"OVERLAY_SOURCE\",\"RECENCY_STATUS_96NK\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multivariate Feature Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Testing Different Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the imputer and gain an idea of the accuracy we can achieve through the use of different estimators, we applied this method to a known subset of our data. Strategy: \n",
    "- Create a subset without NaNs from the complete dataset;\n",
    "- In the new subset, assign NaNs randomly to the columns DONOR_AGE and INCOME_GROUP;\n",
    "- Estimate the missing values with the imputer, using different estimators;\n",
    "- Evaluate the performance by calculating the mean squared error between the original and estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:00.916311Z",
     "start_time": "2020-12-30T23:48:00.893742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a subset without NaNs from the complete dataset;\n",
    "df_no_nan = df[df.iloc[:,:].notna().all(1)]\n",
    "np.any(df_no_nan.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:01.039406Z",
     "start_time": "2020-12-30T23:48:00.923303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaNs introduced:\n",
      " DONOR_AGE        9.97697\n",
      "INCOME_GROUP    10.02632\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# In the new subset, assign NaNs randomly to the columns DONOR_AGE and INCOME_GROUP;\n",
    "sub_for_nan = df_no_nan[['DONOR_AGE','INCOME_GROUP']]\n",
    "\n",
    "ix = [(row, col) for row in range(sub_for_nan.shape[0]) for col in range(sub_for_nan.shape[1])]\n",
    "for row, col in random.sample(ix, int(round(.1*len(ix)))):\n",
    "    sub_for_nan.iat[row, col] = np.nan   \n",
    "\n",
    "# Percentage should be 10%\n",
    "print('Percentage of NaNs introduced:\\n', sub_for_nan.isnull().sum()/len(sub_for_nan)*100)\n",
    "\n",
    "# Adding the new columns with NaNs to the subset\n",
    "df_nan = df_no_nan.copy()\n",
    "df_nan['DONOR_AGE'] = sub_for_nan['DONOR_AGE'].values\n",
    "df_nan['INCOME_GROUP'] = sub_for_nan['INCOME_GROUP'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:04.006227Z",
     "start_time": "2020-12-30T23:48:01.042092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the Bayesian Ridge Estimator: 0.56\n",
      "MSE for the KNN Estimator: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Estimate the missing values with the imputer, using different estimators;\n",
    "\n",
    "# Bayesian Ridge Estimator\n",
    "imputer_bayes = IterativeImputer(random_state=0)\n",
    "bayes = imputer_bayes.fit_transform(df_nan.values)\n",
    "bayes_mse = mean_squared_error(df_no_nan, bayes)\n",
    "print('MSE for the Bayesian Ridge Estimator:', round(bayes_mse, 2))\n",
    "\n",
    "# KNN estimator\n",
    "regressor = KNeighborsRegressor()\n",
    "imputer_knn = IterativeImputer(estimator=regressor, random_state=0)\n",
    "knn = imputer_knn.fit_transform(df_nan.values)\n",
    "knn_mse = mean_squared_error(df_no_nan, knn)\n",
    "print('MSE for the KNN Estimator:', round(knn_mse, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian Ridge estimator displays a lower error in regard to the KNN estimator. Therefore, we will use the default estimator to impute the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Imputation of NaNs with Bayesian Ridge Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:06.985556Z",
     "start_time": "2020-12-30T23:48:04.010762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence of NaNs in the dataset: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>MONTHS_SINCE_ORIGIN</th>\n",
       "      <th>DONOR_AGE</th>\n",
       "      <th>IN_HOUSE</th>\n",
       "      <th>SES</th>\n",
       "      <th>CLUSTER_CODE</th>\n",
       "      <th>INCOME_GROUP</th>\n",
       "      <th>MOR_HIT_RATE</th>\n",
       "      <th>MEDIAN_HOME_VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>LAST_GIFT_AMT</th>\n",
       "      <th>CARD_PROM_12</th>\n",
       "      <th>NUMBER_PROM_12</th>\n",
       "      <th>MONTHS_SINCE_LAST_GIFT</th>\n",
       "      <th>MONTHS_SINCE_FIRST_GIFT</th>\n",
       "      <th>FILE_CARD_GIFT</th>\n",
       "      <th>URBANICITY_e</th>\n",
       "      <th>DONOR_GENDER_e</th>\n",
       "      <th>OVERLAY_SOURCE_e</th>\n",
       "      <th>RECENCY_STATUS_96NK_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>62.695162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_B  TARGET_D  MONTHS_SINCE_ORIGIN  DONOR_AGE  IN_HOUSE  SES  \\\n",
       "0       1.0      10.0                137.0  79.000000       0.0  2.0   \n",
       "1       0.0       0.0                113.0  75.000000       0.0  1.0   \n",
       "2       0.0       0.0                 92.0  62.695162       0.0  2.0   \n",
       "3       0.0       0.0                101.0  74.000000       0.0  2.0   \n",
       "4       0.0       0.0                101.0  63.000000       0.0  3.0   \n",
       "\n",
       "   CLUSTER_CODE  INCOME_GROUP  MOR_HIT_RATE  MEDIAN_HOME_VALUE  ...  \\\n",
       "0          45.0           7.0           0.0              334.0  ...   \n",
       "1          11.0           5.0           0.0             2388.0  ...   \n",
       "2           4.0           6.0           0.0             1688.0  ...   \n",
       "3          49.0           2.0           8.0              514.0  ...   \n",
       "4           8.0           3.0           0.0              452.0  ...   \n",
       "\n",
       "   LAST_GIFT_AMT  CARD_PROM_12  NUMBER_PROM_12  MONTHS_SINCE_LAST_GIFT  \\\n",
       "0           17.0           7.0            21.0                     7.0   \n",
       "1           19.0          11.0            32.0                     6.0   \n",
       "2           15.0          11.0            33.0                     6.0   \n",
       "3           25.0           6.0            19.0                    18.0   \n",
       "4           10.0           9.0            20.0                    19.0   \n",
       "\n",
       "   MONTHS_SINCE_FIRST_GIFT  FILE_CARD_GIFT  URBANICITY_e  DONOR_GENDER_e  \\\n",
       "0                    122.0            12.0           1.0             1.0   \n",
       "1                    105.0            16.0           2.0             0.0   \n",
       "2                     92.0            12.0           4.0             0.0   \n",
       "3                     92.0             3.0           1.0             0.0   \n",
       "4                     91.0             6.0           4.0             1.0   \n",
       "\n",
       "   OVERLAY_SOURCE_e  RECENCY_STATUS_96NK_e  \n",
       "0               3.0                    4.0  \n",
       "1               3.0                    4.0  \n",
       "2               0.0                    0.0  \n",
       "3               0.0                    0.0  \n",
       "4               3.0                    0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputation with default estimator\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "imp_arr = imputer.fit_transform(df.values)\n",
    "\n",
    "# Dataset without missing values\n",
    "df_clean = pd.DataFrame(imp_arr)\n",
    "df_clean.columns = df.columns\n",
    "\n",
    "# Testing if any NaN remains\n",
    "print('Presence of NaNs in the dataset:', np.any(df_clean.isnull()))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Task 2.1, we need to find association rules in the dataset. Therefore, it is helpful to aggregate the non-categorical variables in bins in order to create categorical versions of said variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:07.374288Z",
     "start_time": "2020-12-30T23:48:06.988773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>MONTHS_SINCE_ORIGIN</th>\n",
       "      <th>DONOR_AGE</th>\n",
       "      <th>IN_HOUSE</th>\n",
       "      <th>SES</th>\n",
       "      <th>CLUSTER_CODE</th>\n",
       "      <th>INCOME_GROUP</th>\n",
       "      <th>MOR_HIT_RATE</th>\n",
       "      <th>MEDIAN_HOME_VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>LIFETIME_AVG_GIFT_AMT_BIN</th>\n",
       "      <th>LIFETIME_GIFT_RANGE_BIN</th>\n",
       "      <th>LAST_GIFT_AMT_BIN</th>\n",
       "      <th>CARD_PROM_12_BIN</th>\n",
       "      <th>NUMBER_PROM_12_BIN</th>\n",
       "      <th>MONTHS_SINCE_LAST_GIFT_BIN</th>\n",
       "      <th>MONTHS_SINCE_FIRST_GIFT_BIN</th>\n",
       "      <th>FILE_CARD_GIFT_BIN</th>\n",
       "      <th>INCOME_GROUP_BIN</th>\n",
       "      <th>RECENCY_STATUS_96NK_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(10.0, 15.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(3.0, 9.0]</td>\n",
       "      <td>(20.0, 30.0]</td>\n",
       "      <td>(-0.1, 8.0]</td>\n",
       "      <td>(120.0, 260.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(6.4, 8.337]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(15.0, 201.67]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(9.0, 14.0]</td>\n",
       "      <td>(30.0, 64.0]</td>\n",
       "      <td>(-0.1, 8.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(4.4, 5.4]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>62.695162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(10.0, 15.0]</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(9.0, 14.0]</td>\n",
       "      <td>(30.0, 64.0]</td>\n",
       "      <td>(-0.1, 8.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(5.4, 6.4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(5.0, 10.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(3.0, 9.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(16.0, 24.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(-0.1, 10.0]</td>\n",
       "      <td>(1.4, 2.4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(5.0, 10.0]</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(3.0, 9.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(16.0, 24.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(-0.1, 10.0]</td>\n",
       "      <td>(2.4, 3.4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_B  TARGET_D  MONTHS_SINCE_ORIGIN  DONOR_AGE  IN_HOUSE  SES  \\\n",
       "0       1.0      10.0                137.0  79.000000       0.0  2.0   \n",
       "1       0.0       0.0                113.0  75.000000       0.0  1.0   \n",
       "2       0.0       0.0                 92.0  62.695162       0.0  2.0   \n",
       "3       0.0       0.0                101.0  74.000000       0.0  2.0   \n",
       "4       0.0       0.0                101.0  63.000000       0.0  3.0   \n",
       "\n",
       "   CLUSTER_CODE  INCOME_GROUP  MOR_HIT_RATE  MEDIAN_HOME_VALUE  ...  \\\n",
       "0          45.0           7.0           0.0              334.0  ...   \n",
       "1          11.0           5.0           0.0             2388.0  ...   \n",
       "2           4.0           6.0           0.0             1688.0  ...   \n",
       "3          49.0           2.0           8.0              514.0  ...   \n",
       "4           8.0           3.0           0.0              452.0  ...   \n",
       "\n",
       "   LIFETIME_AVG_GIFT_AMT_BIN  LIFETIME_GIFT_RANGE_BIN  LAST_GIFT_AMT_BIN  \\\n",
       "0               (10.0, 15.0]             (15.0, 30.0]       (15.0, 30.0]   \n",
       "1             (15.0, 201.67]             (15.0, 30.0]       (15.0, 30.0]   \n",
       "2               (10.0, 15.0]             (-0.1, 15.0]       (-0.1, 15.0]   \n",
       "3                (5.0, 10.0]             (15.0, 30.0]       (15.0, 30.0]   \n",
       "4                (5.0, 10.0]             (-0.1, 15.0]       (-0.1, 15.0]   \n",
       "\n",
       "   CARD_PROM_12_BIN  NUMBER_PROM_12_BIN  MONTHS_SINCE_LAST_GIFT_BIN  \\\n",
       "0        (3.0, 9.0]        (20.0, 30.0]                 (-0.1, 8.0]   \n",
       "1       (9.0, 14.0]        (30.0, 64.0]                 (-0.1, 8.0]   \n",
       "2       (9.0, 14.0]        (30.0, 64.0]                 (-0.1, 8.0]   \n",
       "3        (3.0, 9.0]        (10.0, 20.0]                (16.0, 24.0]   \n",
       "4        (3.0, 9.0]        (10.0, 20.0]                (16.0, 24.0]   \n",
       "\n",
       "   MONTHS_SINCE_FIRST_GIFT_BIN  FILE_CARD_GIFT_BIN  INCOME_GROUP_BIN  \\\n",
       "0               (120.0, 260.0]        (10.0, 20.0]      (6.4, 8.337]   \n",
       "1                (80.0, 120.0]        (10.0, 20.0]        (4.4, 5.4]   \n",
       "2                (80.0, 120.0]        (10.0, 20.0]        (5.4, 6.4]   \n",
       "3                (80.0, 120.0]        (-0.1, 10.0]        (1.4, 2.4]   \n",
       "4                (80.0, 120.0]        (-0.1, 10.0]        (2.4, 3.4]   \n",
       "\n",
       "   RECENCY_STATUS_96NK_e  \n",
       "0                    4.0  \n",
       "1                    4.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.insert(df_clean.shape[1]-1,'DONOR_AGE_BIN',pd.cut(df_clean['DONOR_AGE'], [-0.1, 18, 30, 50, 70, df_clean['DONOR_AGE'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MONTHS_SINCE_ORIGIN_BIN',pd.cut(df_clean['MONTHS_SINCE_ORIGIN'], [-0.1, 40, 70, 100, df_clean['MONTHS_SINCE_ORIGIN'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MOR_HIT_RATE_BIN',pd.cut(df_clean['MOR_HIT_RATE'], [-0.1, 30, 120, 190, df_clean['MOR_HIT_RATE'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MEDIAN_HOME_VALUE_BIN',pd.cut(df_clean['MEDIAN_HOME_VALUE'], [-0.1, 1000, 2500, 4000, df_clean['MEDIAN_HOME_VALUE'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MEDIAN_HOUSEHOLD_INCOME_BIN',pd.cut(df_clean['MEDIAN_HOUSEHOLD_INCOME'], [-0.1, 200, 500, 1000, df_clean['MEDIAN_HOUSEHOLD_INCOME'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'PCT_OWNER_OCCUPIED_BIN',pd.cut(df_clean['PCT_OWNER_OCCUPIED'], [-0.1, 25, 50, 75, df_clean['PCT_OWNER_OCCUPIED'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'PER_CAPITA_INCOME_BIN',pd.cut(df_clean['PER_CAPITA_INCOME'], [-0.1, 15000, 25000, 75000, 125000, df_clean['PER_CAPITA_INCOME'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'PCT_ATTRIBUTE1_BIN',pd.cut(df_clean['PCT_ATTRIBUTE1'], [-0.1, 25, 50, 75, df_clean['PCT_ATTRIBUTE1'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'PCT_ATTRIBUTE2_BIN',pd.cut(df_clean['PCT_ATTRIBUTE2'], [-0.1, 25, 50, 75, df_clean['PCT_ATTRIBUTE2'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'PCT_ATTRIBUTE3_BIN',pd.cut(df_clean['PCT_ATTRIBUTE3'], [-0.1, 25, 50, 75, df_clean['PCT_ATTRIBUTE3'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'PCT_ATTRIBUTE4_BIN',pd.cut(df_clean['PCT_ATTRIBUTE4'], [-0.1, 25, 50, 75, df_clean['PCT_ATTRIBUTE4'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'RECENT_RESPONSE_PROP_BIN',pd.cut(df_clean['RECENT_RESPONSE_PROP'], [-0.1, 0.25, 0.5, 0.75, df_clean['RECENT_RESPONSE_PROP'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'RECENT_AVG_GIFT_AMT_BIN',pd.cut(df_clean['RECENT_AVG_GIFT_AMT'], [-0.1, 5, 10, 18, df_clean['RECENT_AVG_GIFT_AMT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'RECENT_CARD_RESPONSE_PROP_BIN',pd.cut(df_clean['RECENT_CARD_RESPONSE_PROP'], [-0.1, 0.25, 0.5, 0.75, df_clean['RECENT_CARD_RESPONSE_PROP'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'RECENT_AVG_CARD_GIFT_AMT_BIN',pd.cut(df_clean['RECENT_AVG_CARD_GIFT_AMT'], [-0.1, 10, 20, 30, df_clean['RECENT_AVG_CARD_GIFT_AMT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'RECENT_RESPONSE_COUNT_BIN',pd.cut(df_clean['RECENT_RESPONSE_COUNT'], [-0.1, 4, 8, 12, df_clean['RECENT_RESPONSE_COUNT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'RECENT_CARD_RESPONSE_COUNT_BIN',pd.cut(df_clean['RECENT_CARD_RESPONSE_COUNT'], [-0.1, 0.1, 3, 6, df_clean['RECENT_CARD_RESPONSE_COUNT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MONTHS_SINCE_LAST_PROM_RESP_BIN',pd.cut(df_clean['MONTHS_SINCE_LAST_PROM_RESP'], [-0.1, 0.1, 12, 20, 28, df_clean['MONTHS_SINCE_LAST_PROM_RESP'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LIFETIME_CARD_PROM_BIN',pd.cut(df_clean['LIFETIME_CARD_PROM'], [-0.1, 15, 30, 45, df_clean['LIFETIME_CARD_PROM'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LIFETIME_PROM_BIN',pd.cut(df_clean['LIFETIME_PROM'], [-0.1, 50, 100, 150, df_clean['LIFETIME_PROM'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LIFETIME_GIFT_AMOUNT_BIN',pd.cut(df_clean['LIFETIME_GIFT_AMOUNT'], [-0.1, 0.1, 25, 60, 150, df_clean['LIFETIME_GIFT_AMOUNT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LIFETIME_GIFT_COUNT_BIN',pd.cut(df_clean['LIFETIME_GIFT_COUNT'], [-0.1, 0.1, 25, 50, 75, df_clean['LIFETIME_GIFT_COUNT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LIFETIME_AVG_GIFT_AMT_BIN',pd.cut(df_clean['LIFETIME_AVG_GIFT_AMT'], [-0.1, 5, 10, 15, df_clean['LIFETIME_AVG_GIFT_AMT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LIFETIME_GIFT_RANGE_BIN',pd.cut(df_clean['LIFETIME_GIFT_RANGE'], [-0.1, 15, 30, 45, df_clean['LIFETIME_GIFT_RANGE'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'LAST_GIFT_AMT_BIN',pd.cut(df_clean['LAST_GIFT_AMT'], [-0.1, 15, 30, 45, df_clean['LAST_GIFT_AMT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'CARD_PROM_12_BIN',pd.cut(df_clean['CARD_PROM_12'], [-0.1, 3, 9, 14, df_clean['CARD_PROM_12'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'NUMBER_PROM_12_BIN',pd.cut(df_clean['NUMBER_PROM_12'], [-0.1, 10, 20, 30, df_clean['NUMBER_PROM_12'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MONTHS_SINCE_LAST_GIFT_BIN',pd.cut(df_clean['MONTHS_SINCE_LAST_GIFT'], [-0.1, 8, 16, 24, df_clean['MONTHS_SINCE_LAST_GIFT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'MONTHS_SINCE_FIRST_GIFT_BIN',pd.cut(df_clean['MONTHS_SINCE_FIRST_GIFT'], [-0.1, 40, 80, 120, df_clean['MONTHS_SINCE_FIRST_GIFT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'FILE_CARD_GIFT_BIN',pd.cut(df_clean['FILE_CARD_GIFT'], [-0.1, 10, 20, 30, df_clean['FILE_CARD_GIFT'].max()]))\n",
    "df_clean.insert(df_clean.shape[1]-1,'INCOME_GROUP_BIN',pd.cut(df_clean['INCOME_GROUP'], [-0.1, 1.4, 2.4, 3.4, 4.4, 5.4, 6.4, df_clean['INCOME_GROUP'].max()]))\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Class Atribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the initial instructions, we have to create a new column 'DONATION_TYPE' from the column 'TARGET_D'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:07.481413Z",
     "start_time": "2020-12-30T23:48:07.377412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_B</th>\n",
       "      <th>TARGET_D</th>\n",
       "      <th>MONTHS_SINCE_ORIGIN</th>\n",
       "      <th>DONOR_AGE</th>\n",
       "      <th>IN_HOUSE</th>\n",
       "      <th>SES</th>\n",
       "      <th>CLUSTER_CODE</th>\n",
       "      <th>INCOME_GROUP</th>\n",
       "      <th>MOR_HIT_RATE</th>\n",
       "      <th>MEDIAN_HOME_VALUE</th>\n",
       "      <th>...</th>\n",
       "      <th>LIFETIME_GIFT_RANGE_BIN</th>\n",
       "      <th>LAST_GIFT_AMT_BIN</th>\n",
       "      <th>CARD_PROM_12_BIN</th>\n",
       "      <th>NUMBER_PROM_12_BIN</th>\n",
       "      <th>MONTHS_SINCE_LAST_GIFT_BIN</th>\n",
       "      <th>MONTHS_SINCE_FIRST_GIFT_BIN</th>\n",
       "      <th>FILE_CARD_GIFT_BIN</th>\n",
       "      <th>INCOME_GROUP_BIN</th>\n",
       "      <th>RECENCY_STATUS_96NK_e</th>\n",
       "      <th>DONATION_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(3.0, 9.0]</td>\n",
       "      <td>(20.0, 30.0]</td>\n",
       "      <td>(-0.1, 8.0]</td>\n",
       "      <td>(120.0, 260.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(6.4, 8.337]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(9.0, 14.0]</td>\n",
       "      <td>(30.0, 64.0]</td>\n",
       "      <td>(-0.1, 8.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(4.4, 5.4]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>62.695162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(9.0, 14.0]</td>\n",
       "      <td>(30.0, 64.0]</td>\n",
       "      <td>(-0.1, 8.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(5.4, 6.4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(15.0, 30.0]</td>\n",
       "      <td>(3.0, 9.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(16.0, 24.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(-0.1, 10.0]</td>\n",
       "      <td>(1.4, 2.4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(-0.1, 15.0]</td>\n",
       "      <td>(3.0, 9.0]</td>\n",
       "      <td>(10.0, 20.0]</td>\n",
       "      <td>(16.0, 24.0]</td>\n",
       "      <td>(80.0, 120.0]</td>\n",
       "      <td>(-0.1, 10.0]</td>\n",
       "      <td>(2.4, 3.4]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_B  TARGET_D  MONTHS_SINCE_ORIGIN  DONOR_AGE  IN_HOUSE  SES  \\\n",
       "0       1.0      10.0                137.0  79.000000       0.0  2.0   \n",
       "1       0.0       0.0                113.0  75.000000       0.0  1.0   \n",
       "2       0.0       0.0                 92.0  62.695162       0.0  2.0   \n",
       "3       0.0       0.0                101.0  74.000000       0.0  2.0   \n",
       "4       0.0       0.0                101.0  63.000000       0.0  3.0   \n",
       "\n",
       "   CLUSTER_CODE  INCOME_GROUP  MOR_HIT_RATE  MEDIAN_HOME_VALUE  ...  \\\n",
       "0          45.0           7.0           0.0              334.0  ...   \n",
       "1          11.0           5.0           0.0             2388.0  ...   \n",
       "2           4.0           6.0           0.0             1688.0  ...   \n",
       "3          49.0           2.0           8.0              514.0  ...   \n",
       "4           8.0           3.0           0.0              452.0  ...   \n",
       "\n",
       "   LIFETIME_GIFT_RANGE_BIN  LAST_GIFT_AMT_BIN  CARD_PROM_12_BIN  \\\n",
       "0             (15.0, 30.0]       (15.0, 30.0]        (3.0, 9.0]   \n",
       "1             (15.0, 30.0]       (15.0, 30.0]       (9.0, 14.0]   \n",
       "2             (-0.1, 15.0]       (-0.1, 15.0]       (9.0, 14.0]   \n",
       "3             (15.0, 30.0]       (15.0, 30.0]        (3.0, 9.0]   \n",
       "4             (-0.1, 15.0]       (-0.1, 15.0]        (3.0, 9.0]   \n",
       "\n",
       "   NUMBER_PROM_12_BIN  MONTHS_SINCE_LAST_GIFT_BIN  \\\n",
       "0        (20.0, 30.0]                 (-0.1, 8.0]   \n",
       "1        (30.0, 64.0]                 (-0.1, 8.0]   \n",
       "2        (30.0, 64.0]                 (-0.1, 8.0]   \n",
       "3        (10.0, 20.0]                (16.0, 24.0]   \n",
       "4        (10.0, 20.0]                (16.0, 24.0]   \n",
       "\n",
       "   MONTHS_SINCE_FIRST_GIFT_BIN  FILE_CARD_GIFT_BIN  INCOME_GROUP_BIN  \\\n",
       "0               (120.0, 260.0]        (10.0, 20.0]      (6.4, 8.337]   \n",
       "1                (80.0, 120.0]        (10.0, 20.0]        (4.4, 5.4]   \n",
       "2                (80.0, 120.0]        (10.0, 20.0]        (5.4, 6.4]   \n",
       "3                (80.0, 120.0]        (-0.1, 10.0]        (1.4, 2.4]   \n",
       "4                (80.0, 120.0]        (-0.1, 10.0]        (2.4, 3.4]   \n",
       "\n",
       "   RECENCY_STATUS_96NK_e  DONATION_TYPE  \n",
       "0                    4.0              D  \n",
       "1                    4.0            nan  \n",
       "2                    0.0            nan  \n",
       "3                    0.0            nan  \n",
       "4                    0.0            nan  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['DONATION_TYPE'] = np.where(df_clean['TARGET_D'] >= 50,'A', \n",
    "                               np.where((df_clean['TARGET_D'] >= 20) & (df_clean['TARGET_D'] < 50),'B',\n",
    "                                        np.where((df_clean['TARGET_D'] >= 13) & (df_clean['TARGET_D'] < 20),'C',\n",
    "                                                 np.where((df_clean['TARGET_D'] >= 10) & (df_clean['TARGET_D'] < 13),'D',\n",
    "                                                          np.where((df_clean['TARGET_D'] < 10) & (df_clean['TARGET_D'] > 0),'E', np.nan)))))\n",
    "\n",
    "# The new column appears as the last column of the dataset\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:07.500537Z",
     "start_time": "2020-12-30T23:48:07.487288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'nan', 'E', 'C', 'B', 'A'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['DONATION_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-donors, the donation is assigned as a non-official 'nan' to avoid confusion with low donations (DONATION_TYPE == E). We will assign it as an official NaN for consistency purposes. However, these entries are never considered since the data has to be preprocessed before each task, eliminating either the non-donors entries or the entire DONATION_TYPE column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:07.550262Z",
     "start_time": "2020-12-30T23:48:07.505457Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean['DONATION_TYPE'].replace('nan', np.nan, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Saving Cleaned Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now clean and ready to be analysed in Tasks 1 and 2. As our project is organized in different notebooks, we have to save the data in a .csv formt to be read in each task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T23:48:11.718211Z",
     "start_time": "2020-12-30T23:48:07.555691Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save dataset as .csv file\n",
    "df_clean.to_csv(r'donors_dataset_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
